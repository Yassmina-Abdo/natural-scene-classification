{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CI_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yassmina-Abdo/natural-scene-classification/blob/main/scene_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYvFZrpGSCNM",
        "outputId": "8c138d0a-05e3-468b-b561-75380f82201a"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Jj3Ukz343Ya"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4VlN5HpYPiA"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5fAF8aETfgk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import osimport tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers, activations\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1elh2l05Q_f"
      },
      "source": [
        "# Part1-Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmlFAJB05hTU"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmiFAmzb5KsK",
        "outputId": "f9607c65-5cc9-4373-c604-a517e3f6420d"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   horizontal_flip = True\n",
        "                                   )\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Scenes_training_set/',\n",
        "                                target_size=(150,150),\n",
        "                                batch_size=32,\n",
        "                                class_mode='categorical')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12564 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNZPhMZzubZl"
      },
      "source": [
        "### Preprocessing the Testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aop66vzNug1F",
        "outputId": "3e51d8c4-51ee-4561-a459-77fa9a696b82"
      },
      "source": [
        "ts_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "testing_set = ts_datagen.flow_from_directory('/content/drive/MyDrive/My_Scenes_testing_set',\n",
        "                               target_size=(150,150),\n",
        "                               batch_size=32,\n",
        "                               class_mode='categorical',\n",
        "                               )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1470 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxJLAowt8FXb"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuER0tiNdIIT"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=[150, 150, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "\n",
        "\n",
        "  cnn.add(tf.keras.layers.Flatten())\n",
        "  cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "  cnn.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "  cnn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "  cnn.add(tf.keras.layers.Dense(units=6, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhSYA11tcNL-"
      },
      "source": [
        "filepath = \"model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', \n",
        "                        verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "early = EarlyStopping(monitor=\"val_loss\", \n",
        "                      mode=\"min\", \n",
        "                      patience=4, restore_best_weights=True)\n",
        "callbacks_list = [checkpoint, early]\n",
        "\n",
        "\n",
        "cnn.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "cnn.fit(x = training_set, validation_data = testing_set, epochs = 100, callbacks=callbacks_list) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We_Fc72gcPxY"
      },
      "source": [
        "## Predict\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvEceN0nlyyI"
      },
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "images = []\n",
        "images_name = []\n",
        "folder_path = '/content/drive/MyDrive/Scenes_testing_test/'\n",
        "\n",
        "for img in os.listdir(folder_path):\n",
        "    images_name.append(img)\n",
        "    img = os.path.join(folder_path, img)\n",
        "    img = image.load_img(img, target_size=(150, 150))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    images.append(img)\n",
        "\n",
        "images = np.vstack(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFHScLoXnxLW"
      },
      "source": [
        "cnn.load_weights('/content/drive/MyDrive/model.h5')\n",
        "classes = np.argmax(cnn.predict(images), axis=-1)\n",
        "images_name = np.array(images_name)\n",
        "import pandas as pd\n",
        "dataset = pd.DataFrame({'Image': images_name, 'Label': list(classes)}, columns=['Image', 'Label'])\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmVQSmxK3UDv"
      },
      "source": [
        "dataset.to_csv(r'predictions.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npjR1Qwmkti4"
      },
      "source": [
        "dataset.Label.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqqVWzeUmae4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}